{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsPsmkmDiTQ1QBnmH2Mxep"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## current"
      ],
      "metadata": {
        "id": "75O4OU919Nu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Step 0/8 : Colab Environment Setup\n",
        "# ============================================================\n",
        "# âš ï¸  This block is intended for Google Colab development only.\n",
        "#     When running as CLI (grader.py), this section will be skipped.\n",
        "print(\"ğŸ”¹ Step 0/8: Installing minimal dependencies and setting up environment...\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0.1 Mount Google Drive\n",
        "# ------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    drive.mount(\"/content/drive\")\n",
        "    print(\"âœ… Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Drive mount skipped or failed: {e}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0.2 Dependency check & install\n",
        "# ------------------------------------------------------------\n",
        "print(\"ğŸ“¦ Checking required libraries...\")\n",
        "!pip install -q nbformat==5.10.4 pandas==2.2.2\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0.3 Suppress warnings (Deprecation, Future)\n",
        "# ------------------------------------------------------------\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "print(\"ğŸ”‡ Deprecation and Future warnings are suppressed.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 0.4 Set working directory\n",
        "# ------------------------------------------------------------\n",
        "import os, sys\n",
        "PKG_PARENT = \"/content/drive/MyDrive/Colab Notebooks/autograder/src\"\n",
        "\n",
        "try:\n",
        "    os.chdir(PKG_PARENT)\n",
        "    sys.path.append(PKG_PARENT)\n",
        "    print(f\"ğŸ“ Working directory set to: {PKG_PARENT}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Directory change failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r96opOMonUYI",
        "outputId": "1512366c-dcf3-4924-fa7e-56f1780fd8d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Step 0/8: Installing minimal dependencies and setting up environment...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive mounted successfully.\n",
            "ğŸ“¦ Checking required libraries...\n",
            "ğŸ”‡ Deprecation and Future warnings are suppressed.\n",
            "ğŸ“ Working directory set to: /content/drive/MyDrive/Colab Notebooks/autograder/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Step 1/8 : Importing libraries & initializing\n",
        "# ============================================================\n",
        "print(\"ğŸ”¹ Step 1/8: Importing libraries & initializing...\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1.1. Standard & common libraries\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "import datetime as dt\n",
        "\n",
        "import nbformat\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1.2. AutoGrader internal modules\n",
        "# ------------------------------------------------------------\n",
        "from autograder.policy import (\n",
        "    BASE_SCORE,\n",
        "    PENALTY_REQUIRED_MISS,\n",
        "    PENALTY_REQUIRED_MISMATCH,\n",
        "    PENALTY_OPTIONAL_MISS,\n",
        "    outputs_equal,\n",
        "    decide_status_and_match,\n",
        ")\n",
        "\n",
        "from autograder.io_utils import (\n",
        "    KST,\n",
        "    now_kst,\n",
        "    extract_id_and_name,\n",
        "    mtime_kst,\n",
        "    load_config,\n",
        ")\n",
        "\n",
        "from autograder.nb_utils import (\n",
        "    LABEL_PATTERN,\n",
        "    _normalize_code,\n",
        "    _extract_label,\n",
        "    _label_map,\n",
        "    _nb_fingerprint,\n",
        "    _cell_output_text,\n",
        "    _indexes_with_labels,\n",
        "    _sim,\n",
        "    _label_key_robust,\n",
        ")\n",
        "\n",
        "from autograder.report import (\n",
        "    build_stats_block,\n",
        "    build_excluded_summary_line,\n",
        "    render_run_summary,\n",
        "    build_run_log_lines,\n",
        ")\n",
        "\n",
        "from autograder.label_tagging import (\n",
        "    template_label_tagging,\n",
        "    classify_labels,\n",
        ")\n",
        "\n",
        "from autograder.similarity import compute_similarity_pairs\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1.3. Load session config & define key paths\n",
        "# ------------------------------------------------------------\n",
        "# Select session (ì°¨ì‹œ) & mode\n",
        "session = load_config(\"autograder/configs/sessions.toml\", 9, \"DEV\")\n",
        "# session = load_config(\"autograder/configs/sessions.toml\", 9, \"PROD\")\n",
        "\n",
        "# Core paths\n",
        "TEMPLATE_PATH = Path(session[\"template_path\"])   # í…œí”Œë¦¿\n",
        "ANSWER_PATH   = Path(session[\"answer_path\"])     # ì •ë‹µ\n",
        "SUBMIT_DIR    = Path(session[\"submit_dir\"])      # ì œì¶œíŒŒì¼ë“¤\n",
        "OUT_DIR       = Path(session[\"out_dir\"])         # Autograde ì¶œë ¥ ë£¨íŠ¸\n",
        "\n",
        "# Tagged template & audit\n",
        "TAGGED_TEMP_PATH = OUT_DIR / \"tagged_template.ipynb\"\n",
        "TAG_AUDIT_PATH   = OUT_DIR / \"tag_audit.csv\"\n",
        "\n",
        "# Execution output folder\n",
        "RUN_TS   = now_kst().strftime(\"%Y%m%d_%H%M%S\")\n",
        "EXEC_DIR = OUT_DIR / \"executed\" / RUN_TS\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "EXEC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  Step 2/8 : í…œí”Œë¦¿ ë ˆì´ë¸” íƒœê¹…\n",
        "# ============================================================\n",
        "print(\"ğŸ”¹ Step 2/8: Tagging template (required / optional_ex) by labels...\")\n",
        "\n",
        "if not Path(TAGGED_TEMP_PATH).exists():\n",
        "    template_label_tagging(TEMPLATE_PATH, ANSWER_PATH, TAGGED_TEMP_PATH, TAG_AUDIT_PATH)\n",
        "    print(\"âœ… Tagged template created!\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ Tagged template already exists.\")\n",
        "\n",
        "# ============================================================\n",
        "#  Step 3/8 : íƒœê¹…ëœ í…œí”Œë¦¿ìœ¼ë¡œë¶€í„° ë ˆì´ë¸” ì •ë³´ íšë“\n",
        "# ============================================================\n",
        "print(\"\\nğŸ”¹ Step 3/8: Reading tagged template and answer (label-based)...\")\n",
        "\n",
        "req_labels, opt_labels, req_idx, opt_idx, template_fp = classify_labels(TAGGED_TEMP_PATH)\n",
        "\n",
        "# ============================================================\n",
        "#  Step 4/8 : ì˜µì…˜/ì„ê³„ê°’ ë° ì´ì „ ê²°ê³¼ ë¡œë“œ\n",
        "# ============================================================\n",
        "print(\"\\nğŸ”¹ Step 4/8: Loading previous summary (if any) and setting thresholds...\")\n",
        "\n",
        "TEMPLATE_SIM_THRESHOLD = 0.98\n",
        "PAIR_SIM_THRESHOLD = 0.99\n",
        "ENABLE_SIMILARITY_CHECK = False   # Falseë¡œ ë°”ê¾¸ë©´ Step 6 ìŠ¤í‚µ\n",
        "\n",
        "\n",
        "prev_ids = set()\n",
        "prev_files = sorted(\n",
        "    Path(OUT_DIR).glob(\"summary_static_with_name_*.csv\"),\n",
        "    key=lambda p: p.stat().st_mtime\n",
        ")\n",
        "\n",
        "if prev_files:\n",
        "    try:\n",
        "        prev_df = pd.read_csv(prev_files[-1], dtype=str)\n",
        "        if \"student_id\" in prev_df.columns:\n",
        "            prev_ids = set(prev_df[\"student_id\"].astype(str))\n",
        "    except Exception:\n",
        "        prev_ids = set()\n",
        "\n",
        "# ============================================================\n",
        "#  Step 5/8 : ì œì¶œë¬¼ ì²˜ë¦¬ (ì±„ì )\n",
        "# ============================================================\n",
        "print(\"\\nğŸ”¹ Step 5/8: Collecting and grading submissions...\")\n",
        "\n",
        "paths = sorted(Path(SUBMIT_DIR).rglob(\"*.ipynb\"))\n",
        "rows, today_rows_tmp = [], []\n",
        "fps, sid2file, sid2name, sid2path = {}, {}, {}, {}\n",
        "\n",
        "EXCLUDED_REQ_ALL, EXCLUDED_OPT_ALL = set(), set()\n",
        "\n",
        "def _label_key(x):\n",
        "    try:\n",
        "        return [int(t) for t in x.split(\".\")]\n",
        "    except Exception:\n",
        "        return [999999]\n",
        "\n",
        "def _exec_and_out_expected(stu_map, ans_map, lab):\n",
        "    \"\"\"\n",
        "    expected_output: ì •ë‹µ ì…€ ì¶œë ¥ ìœ ë¬´(True/False).\n",
        "    - expected_output=True  â†’ í•™ìƒ ì¶œë ¥(stu_out)ì´ ìˆì–´ì•¼ 'ì‹¤í–‰' ì¸ì •\n",
        "    - expected_output=False â†’ ì±„ì  ì œì™¸\n",
        "    ë°˜í™˜: (executed: bool, stu_out_text: str, expected_output: bool)\n",
        "    \"\"\"\n",
        "    sinfo = stu_map.get(lab)\n",
        "    anscell = ans_map.get(lab, {}).get(\"cell\")\n",
        "    ans_out = _cell_output_text(anscell) if anscell else \"\"\n",
        "    expected_output = bool(ans_out)\n",
        "\n",
        "    if not sinfo:\n",
        "        return False, \"\", expected_output\n",
        "\n",
        "    scell = sinfo[\"cell\"]\n",
        "    stu_out = _cell_output_text(scell)\n",
        "    executed = bool(stu_out) if expected_output else (\n",
        "        bool(stu_out) or (scell.get(\"execution_count\") not in (None, 0))\n",
        "    )\n",
        "    return executed, stu_out, expected_output\n",
        "\n",
        "\n",
        "# í…œí”Œë¦¿ ë° ì •ë‹µ ë¡œë“œ\n",
        "tagged_nb = nbformat.read(TAGGED_TEMP_PATH, as_version=4)\n",
        "ans = nbformat.read(ANSWER_PATH, as_version=4)\n",
        "\n",
        "# í…œí”Œë¦¿/ì •ë‹µ/íƒœê¹…ë³¸ ì œì™¸\n",
        "skip_names = {TEMPLATE_PATH.name, ANSWER_PATH.name, TAGGED_TEMP_PATH.name}\n",
        "\n",
        "# ===== ì‹¤ì œ ì±„ì  ë£¨í”„ =====\n",
        "for p in paths:\n",
        "    if p.name in skip_names:\n",
        "        continue\n",
        "\n",
        "    sid, name = extract_id_and_name(p)\n",
        "    sid2name[sid], sid2path[sid] = name, p\n",
        "\n",
        "    try:\n",
        "        nb = nbformat.read(p, as_version=4)\n",
        "    except Exception as e:\n",
        "        rows.append([sid, name, p.name, 0.0, \"ERROR\", \"ipynb íŒŒì‹± ì‹¤íŒ¨\", \"ERROR\", f\"ë…¸íŠ¸ë¶ íŒŒì‹± ì‹¤íŒ¨: {e}\"])\n",
        "        if mtime_kst(p).date() == now_kst().date():\n",
        "            today_rows_tmp.append(rows[-1])\n",
        "        continue\n",
        "\n",
        "    # í…œí”Œë¦¿ ìœ ì‚¬ë„ 0ì  ì²˜ë¦¬\n",
        "    fp = _nb_fingerprint(nb)\n",
        "    fps[sid], sid2file[sid] = fp, p.name\n",
        "    if _sim(fp, template_fp) >= TEMPLATE_SIM_THRESHOLD:\n",
        "        rows.append([sid, name, p.name, 0.0, \"ZERO\", \"í…œí”Œë¦¿ê³¼ ê±°ì˜ ë™ì¼(ì›ë³¸/ë¬´ë³€ê²½)\", \"ZERO\",\n",
        "                     \"í…œí”Œë¦¿ê³¼ ê±°ì˜ ë™ì¼í•˜ì—¬ 0ì  ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\"])\n",
        "        if mtime_kst(p).date() == now_kst().date():\n",
        "            today_rows_tmp.append(rows[-1])\n",
        "        continue\n",
        "\n",
        "    # ë¼ë²¨ ë§µ\n",
        "    stu_lmap, ans_lmap = _label_map(nb), _label_map(ans)\n",
        "\n",
        "    # í•„ìˆ˜/ì˜µì…˜ ë¼ë²¨ ì±„ì \n",
        "    req_missing, req_mismatch, opt_missing = [], [], []\n",
        "    excluded_req, excluded_opt = [], []\n",
        "\n",
        "    for lab in sorted(req_labels, key=_label_key):\n",
        "        executed, stu_out, expected_output = _exec_and_out_expected(stu_lmap, ans_lmap, lab)\n",
        "        if not expected_output:\n",
        "            excluded_req.append(f\"#{lab}\")\n",
        "            continue\n",
        "        anscell = ans_lmap.get(lab, {}).get(\"cell\")\n",
        "        ans_out = _cell_output_text(anscell) if anscell else \"\"\n",
        "        if not executed:\n",
        "            req_missing.append(f\"#{lab}\")\n",
        "            continue\n",
        "        if not outputs_equal(stu_out, ans_out):\n",
        "            req_mismatch.append(f\"#{lab}\")\n",
        "\n",
        "    for lab in sorted(opt_labels, key=_label_key):\n",
        "        executed, stu_out, expected_output = _exec_and_out_expected(stu_lmap, ans_lmap, lab)\n",
        "        if not expected_output:\n",
        "            excluded_opt.append(f\"#{lab}\")\n",
        "            continue\n",
        "        if not executed:\n",
        "            opt_missing.append(f\"#{lab}\")\n",
        "\n",
        "    # ê°ì  ê³„ì‚°\n",
        "    score = BASE_SCORE \\\n",
        "        - PENALTY_REQUIRED_MISS * len(req_missing) \\\n",
        "        - PENALTY_REQUIRED_MISMATCH * len(req_mismatch) \\\n",
        "        - PENALTY_OPTIONAL_MISS * len(opt_missing)\n",
        "\n",
        "    # í”¼ë“œë°± êµ¬ì„±\n",
        "    feedback_lines = []\n",
        "    if req_missing:\n",
        "        feedback_lines.append(f\"[í•„ìˆ˜ ë¯¸ì‹¤í–‰ {len(req_missing)}ê°œ] ì…€: {', '.join(req_missing)}\")\n",
        "    if req_mismatch:\n",
        "        feedback_lines.append(f\"[í•„ìˆ˜ ì¶œë ¥ ë¶ˆì¼ì¹˜ {len(req_mismatch)}ê°œ] ì…€: {', '.join(req_mismatch)}\")\n",
        "    if opt_missing:\n",
        "        feedback_lines.append(f\"[ì—°ìŠµ ë¯¸ì‹¤í–‰ {len(opt_missing)}ê°œ] ì…€: {', '.join(opt_missing)}\")\n",
        "\n",
        "    status, output_match = decide_status_and_match(req_missing, req_mismatch)\n",
        "    reason = \"\" if status == \"OK\" else \"í•„ìˆ˜ ë¯¸ì‹¤í–‰/ë¶ˆì¼ì¹˜ ì¡´ì¬\"\n",
        "\n",
        "    score_line = (\n",
        "        f\"(ì±„ì ) base={BASE_SCORE}\"\n",
        "        f\"{' âˆ’ ' + str(PENALTY_REQUIRED_MISS)    + 'Ã—' + str(len(req_missing))  + '(í•„ìˆ˜ ë¯¸ì‹¤í–‰)' if req_missing else ''}\"\n",
        "        f\"{' âˆ’ ' + str(PENALTY_REQUIRED_MISMATCH)+ 'Ã—' + str(len(req_mismatch)) + '(í•„ìˆ˜ ë¶ˆì¼ì¹˜)' if req_mismatch else ''}\"\n",
        "        f\"{' âˆ’ ' + str(PENALTY_OPTIONAL_MISS)    + 'Ã—' + str(len(opt_missing))  + '(ì—°ìŠµ ë¯¸ì‹¤í–‰)' if opt_missing else ''}\"\n",
        "        f\" = {score}\"\n",
        "    )\n",
        "\n",
        "    feedback = \"\\n\".join(feedback_lines) if feedback_lines else \"ì •ìƒ ì œì¶œë¡œ íŒë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í–ˆìŠµë‹ˆë‹¤!\"\n",
        "    feedback = f\"{feedback}\\n{score_line}\".strip()\n",
        "\n",
        "    rows.append([sid, name, p.name, score, status, reason, output_match, feedback])\n",
        "\n",
        "    if mtime_kst(p).date() == now_kst().date():\n",
        "        today_rows_tmp.append([sid, name, p.name, score, status, reason, output_match, feedback])\n",
        "\n",
        "    EXCLUDED_REQ_ALL.update(excluded_req)\n",
        "    EXCLUDED_OPT_ALL.update(excluded_opt)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  Step 6/8 : ìœ ì‚¬ë„ ë¹„êµ\n",
        "# ============================================================\n",
        "if ENABLE_SIMILARITY_CHECK:\n",
        "    print(\"\\nğŸ”¹ Step 6/8: Computing code similarity pairs (â‰¥ 0.99)...\")\n",
        "    pairs, df_sim = compute_similarity_pairs(\n",
        "        fps=fps,\n",
        "        sid2file=sid2file,\n",
        "        sid2path=sid2path,\n",
        "        sid2name=sid2name,\n",
        "        sim_func=_sim,\n",
        "        threshold=PAIR_SIM_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # ì €ì¥\n",
        "    if not df_sim.empty:\n",
        "        df_sim.to_csv(EXEC_DIR / f\"similar_pairs_{RUN_TS}.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "        df_sim.to_csv(Path(OUT_DIR) / \"similar_pairs_latest.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "else:\n",
        "    print(\"\\nâ© Step 6/8: Similarity check skipped (ENABLE_SIMILARITY_CHECK=False).\")\n",
        "    pairs, df_sim = [], pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  Step 7/8 : ì¶œë ¥ë¬¼ ì €ì¥\n",
        "# ============================================================\n",
        "print(\"\\nğŸ”¹ Step 7/8: Saving outputs...\")\n",
        "\n",
        "summary_df = pd.DataFrame(\n",
        "    rows,\n",
        "    columns=[\"student_id\", \"student_name\", \"file\", \"score\", \"status\", \"reasons\", \"output_match\", \"feedback\"]\n",
        ")\n",
        "\n",
        "# íŒŒì¼ëª… êµ¬ì„±\n",
        "summary_filename_ts = f\"summary_static_with_name_{RUN_TS}.csv\"\n",
        "similar_filename_ts = f\"similar_pairs_{RUN_TS}.csv\"\n",
        "newtoday_filename_ts = f\"new_today_{RUN_TS}.csv\"\n",
        "\n",
        "summary_latest = Path(OUT_DIR) / \"summary_static_with_name_latest.csv\"\n",
        "similar_latest = Path(OUT_DIR) / \"similar_pairs_latest.csv\"\n",
        "newtoday_latest = Path(OUT_DIR) / \"new_today_latest.csv\"\n",
        "\n",
        "# CSV ì €ì¥\n",
        "summary_path_ts = EXEC_DIR / summary_filename_ts\n",
        "summary_df.to_csv(summary_path_ts, index=False, encoding=\"utf-8-sig\")\n",
        "summary_df.to_csv(summary_latest, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "if pairs:\n",
        "    df_sim = pd.DataFrame(\n",
        "        pairs,\n",
        "        columns=[\n",
        "            \"student_a\", \"name_a\", \"file_a\", \"mtime_a_kst\", \"size_a_bytes\",\n",
        "            \"student_b\", \"name_b\", \"file_b\", \"mtime_b_kst\", \"size_b_bytes\",\n",
        "            \"similarity\"\n",
        "        ]\n",
        "    )\n",
        "    df_sim.to_csv(EXEC_DIR / similar_filename_ts, index=False, encoding=\"utf-8-sig\")\n",
        "    df_sim.to_csv(similar_latest, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "df_today = pd.DataFrame(today_rows_tmp, columns=summary_df.columns)\n",
        "df_today.to_csv(EXEC_DIR / newtoday_filename_ts, index=False, encoding=\"utf-8-sig\")\n",
        "df_today.to_csv(newtoday_latest, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# ============================================================\n",
        "#  Step 8/8 : ìš”ì•½ ë° ì‹¤í–‰ ë¡œê·¸\n",
        "# ============================================================\n",
        "print(\"\\nğŸ”¹ Step 8/8: Logging summary...\")\n",
        "\n",
        "prev_ids = prev_ids or set()\n",
        "new_ids = set(summary_df[\"student_id\"].astype(str)) - prev_ids if prev_ids else set(summary_df[\"student_id\"].astype(str))\n",
        "\n",
        "STATS_BLOCK = build_stats_block(summary_df)\n",
        "\n",
        "# CONFIG / ë¡œê·¸ ì €ì¥\n",
        "\n",
        "CONFIG = {\n",
        "    # â”€â”€ Run / Time Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"TODAY_DATE\": now_kst().date(),\n",
        "    \"KST_NOW\": now_kst().strftime(\"%Y-%m-%d %H:%M:%S KST\"),\n",
        "    \"TIMEZONE\": \"KST (UTC+9)\",\n",
        "    \"RUN_TS\": RUN_TS,\n",
        "\n",
        "    # â”€â”€ Directories (as str) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"OUT_DIR\": str(OUT_DIR),\n",
        "    \"EXEC_DIR\": str(EXEC_DIR),\n",
        "    \"SUBMIT_DIR\": str(SUBMIT_DIR),\n",
        "\n",
        "    # â”€â”€ File basenames (name only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"TEMPLATE_FILE\": Path(TEMPLATE_PATH).name,\n",
        "    \"ANSWER_FILE\": Path(ANSWER_PATH).name,\n",
        "    \"TAGGED_TEMP_FILE\": Path(TAGGED_TEMP_PATH).name,\n",
        "    \"TAG_AUDIT_FILE\": Path(TAG_AUDIT_PATH).name,\n",
        "    \"RUN_LOG_FILE\": \"autograde_run.log\",\n",
        "    \"SUMMARY_FILE_LATEST\": Path(summary_latest).name,\n",
        "    \"SIMILAR_FILE_LATEST\": (Path(similar_latest).name if pairs else \"N/A\"),\n",
        "    \"NEWTODAY_FILE_LATEST\": Path(newtoday_latest).name,\n",
        "\n",
        "\n",
        "    # â”€â”€ Full paths (as str) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"TEMPLATE_PATH\": str(TEMPLATE_PATH),\n",
        "    \"ANSWER_PATH\": str(ANSWER_PATH),\n",
        "    \"TAGGED_TEMP_PATH\": str(TAGGED_TEMP_PATH),\n",
        "\n",
        "    # â”€â”€ Scoring / Thresholds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"SIM_THRESHOLD_TEMPLATE\": TEMPLATE_SIM_THRESHOLD,\n",
        "    \"SIM_THRESHOLD_PAIR\": PAIR_SIM_THRESHOLD,\n",
        "    \"SCORE_RULE\": \"base=100; required: miss -1.0, mismatch -0.5; optional: miss -0.2\",\n",
        "\n",
        "    # â”€â”€ Required/Optional cells (counts / indexes / maps) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"REQUIRED_CELL_COUNT\": len(req_labels),\n",
        "    \"OPTIONAL_CELL_COUNT\": len(opt_labels),\n",
        "    \"REQUIRED_CELL_INDEXES\": sorted(list(req_idx)),\n",
        "    \"OPTIONAL_CELL_INDEXES\": sorted(list(opt_idx)),\n",
        "    \"REQUIRED_CELL_MAP\": _indexes_with_labels(tagged_nb, req_idx),\n",
        "    \"OPTIONAL_CELL_MAP\": _indexes_with_labels(tagged_nb, opt_idx),\n",
        "    \"EXCLUDED_REQ_ALL\": \", \".join(sorted(EXCLUDED_REQ_ALL, key=_label_key_robust)) \\\n",
        "                          if EXCLUDED_REQ_ALL else \"ì—†ìŒ\",\n",
        "    \"EXCLUDED_OPT_ALL\": \", \".join(sorted(EXCLUDED_OPT_ALL, key=_label_key_robust)) \\\n",
        "                          if EXCLUDED_OPT_ALL else \"ì—†ìŒ\",\n",
        "\n",
        "    # â”€â”€ Dataset stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    \"TOTAL_CNT\": len(summary_df),\n",
        "    \"NEW_CNT\": len(new_ids),\n",
        "    \"TODAY_CNT\": len(df_today),\n",
        "}\n",
        "log_lines = build_run_log_lines(CONFIG, STATS_BLOCK, new_ids=new_ids)\n",
        "Path(CONFIG[\"OUT_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
        "with open(Path(CONFIG[\"OUT_DIR\"]) / \"autograde_run.log\", \"a\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(log_lines) + \"\\n\")\n",
        "\n",
        "print(\"ğŸ—’ï¸ Log appended to:\", CONFIG[\"RUN_LOG_FILE\"])\n",
        "print(render_run_summary(CONFIG, STATS_BLOCK))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCfoU55ogK0h",
        "outputId": "91449233-8487-49f4-b37a-5b8b86d77972"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Step 1/8: Importing libraries & initializing...\n",
            "ğŸ”¹ Step 2/8: Tagging template (required / optional_ex) by labels...\n",
            "â„¹ï¸ Tagged template already exists.\n",
            "\n",
            "ğŸ”¹ Step 3/8: Reading tagged template and answer (label-based)...\n",
            "\n",
            "ğŸ”¹ Step 4/8: Loading previous summary (if any) and setting thresholds...\n",
            "\n",
            "ğŸ”¹ Step 5/8: Collecting and grading submissions...\n",
            "\n",
            "â© Step 6/8: Similarity check skipped (ENABLE_SIMILARITY_CHECK=False).\n",
            "\n",
            "ğŸ”¹ Step 7/8: Saving outputs...\n",
            "\n",
            "ğŸ”¹ Step 8/8: Logging summary...\n",
            "ğŸ—’ï¸ Log appended to: autograde_run.log\n",
            "âœ… ì™„ë£Œ: /content/drive/MyDrive/Colab Notebooks/2024 ë§ˆì¼€íŒ…ì¡°ì‚¬ë¡ /Autograde/9ì°¨ì‹œ\n",
            "ğŸ•’ ì‹¤í–‰ì‹œê°: 2025-11-04 20:27:58 KST  [KST (UTC+9)]\n",
            "\n",
            "ğŸ“¦ ë°ì´í„° ìš”ì•½\n",
            "  â€¢ ì „ì²´ ì±„ì  í•™ìƒ ìˆ˜ : 112ëª…\n",
            "  â€¢ ìƒˆë¡œ ì±„ì í•œ í•™ìƒ ìˆ˜ : 0ëª…\n",
            "  â€¢ ì˜¤ëŠ˜ ë“¤ì–´ì˜¨ íŒŒì¼(KST 2025-11-04) : 0ê±´\n",
            "\n",
            "ğŸ—‚ ì‚°ì¶œë¬¼/ê²½ë¡œ\n",
            "  â€¢ ì‹¤í–‰ ì‚°ì¶œë¬¼ í´ë” : executed/20251104_202752/\n",
            "  â€¢ ì œì¶œ í´ë”(SUBMIT_DIR) : /content/drive/MyDrive/Colab Notebooks/2024 ë§ˆì¼€íŒ…ì¡°ì‚¬ë¡ /9ì°¨ì‹œ\n",
            "  â€¢ OUT_DIR : /content/drive/MyDrive/Colab Notebooks/2024 ë§ˆì¼€íŒ…ì¡°ì‚¬ë¡ /Autograde/9ì°¨ì‹œ\n",
            "\n",
            "ğŸ§¾ ìµœì‹  ê²°ê³¼ íŒŒì¼\n",
            "  â€¢ ìš”ì•½(SUMMARY)   : summary_static_with_name_latest.csv\n",
            "  â€¢ ìœ ì‚¬ë„(SIMILAR) : N/A\n",
            "  â€¢ Today NEW       : new_today_latest.csv\n",
            "\n",
            "ğŸ“‘ í…œí”Œë¦¿/ì •ë‹µ/íƒœê¹…ë³¸\n",
            "  â€¢ í…œí”Œë¦¿ íŒŒì¼        : MR_09_íŒŒì´ì¬ ê¸°ì´ˆ_í•™ë²ˆ_ì„±ëª….ipynb\n",
            "  â€¢ ì •ë‹µ íŒŒì¼          : MR_09_íŒŒì´ì¬ ê¸°ì´ˆ_í•™ë²ˆ_ì„±ëª…_src.ipynb\n",
            "  â€¢ í…œí”Œë¦¿ íƒœê¹…ë³¸ íŒŒì¼ : tagged_template.ipynb\n",
            "  â€¢ íƒœê·¸ ê°ì‚¬ CSV      : tag_audit.csv\n",
            "\n",
            "âš–ï¸ ì±„ì  ê·œì¹™ / ì„ê³„ê°’\n",
            "  â€¢ SCORE_RULE           : base=100; required: miss -1.0, mismatch -0.5; optional: miss -0.2\n",
            "  â€¢ SIM_THRESHOLD_TEMPLATE : 0.98\n",
            "  â€¢ SIM_THRESHOLD_PAIR     : 0.99\n",
            "\n",
            "ğŸ§© Required / Optional ì…€\n",
            "  â€¢ REQUIRED_CELL_COUNT : 32\n",
            "  â€¢ OPTIONAL_CELL_COUNT : 10\n",
            "  â€¢ ì œì™¸ëœ í•„ìˆ˜ ì…€: #4.1.1\n",
            "  â€¢ ì œì™¸ëœ ì—°ìŠµ ì…€: #1.4.2, #2.2.1\n",
            "\n",
            "ğŸ“Š Score & Distribution Summary\n",
            "SCORE STATS:\n",
            "- mean=95.4, median=99.5, min=0.0\n",
            "STATUS Ã— OUTPUT_MATCH (counts):\n",
            "               |     ZERO |    ERROR |  MISSING | MISMATCH |       OK\n",
            "---------------------------------------------------------------------\n",
            "         ERROR |        0 |        1 |        0 |        0 |        0\n",
            "    INCOMPLETE |        0 |        0 |       14 |       42 |        0\n",
            "            OK |        0 |        0 |        0 |        0 |       53\n",
            "          ZERO |        2 |        0 |        0 |        0 |        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYC_FRCVDX8d"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}